{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9564208-8d41-4a7b-a12e-b13f6b3e3027",
   "metadata": {},
   "source": [
    "# Predictive Data Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f419ae18-5559-43bb-8a6d-b0d1bec4d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, udf, split, when, sin, cos\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer, Pipeline\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Tokenizer\n",
    "from pyspark.ml.regression import LinearRegression, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator \n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator \n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a9825-4d00-420b-88a9-b6490506674b",
   "metadata": {},
   "source": [
    "## Read Hive tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b50299-c3da-4793-b2f1-9b9c87866aeb",
   "metadata": {},
   "source": [
    "### Connect to Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4ecd01-d86b-4de2-b0c0-1e6ca3a67bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add here your team number teamx\n",
    "team = \"team13\"\n",
    "\n",
    "# Location of Hive database in HDFS\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"{} - spark ML\".format(team)) \\\n",
    "        .master(\"yarn\") \\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\") \\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse) \\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\") \\\n",
    "        .config(\"spark.executor.instances\", 8) \\\n",
    "        .config(\"spark.executor.cores\", 1) \\\n",
    "        .config(\"spark.executor.memory\", \"2g\") \\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", \"false\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b4a7e4-7934-4eb6-9b43-46bafd99a20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://hadoop-01.uni.innopolis.ru:4140\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>team13 - spark ML</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fac62286dd8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982d97e-f132-4af8-ba23-c12848742735",
   "metadata": {},
   "source": [
    "### List all databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1c5c347-762d-4e98-89d5-7fd80e79efed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|             default|\n",
      "|             root_db|\n",
      "|     team0_projectdb|\n",
      "|team12_hive_proje...|\n",
      "|    team13_projectdb|\n",
      "|    team14_projectdb|\n",
      "|    team15_projectdb|\n",
      "|    team16_projectdb|\n",
      "|    team17_projectdb|\n",
      "|    team18_projectdb|\n",
      "|    team19_projectdb|\n",
      "|     team1_projectdb|\n",
      "|    team20_projectdb|\n",
      "|    team21_projectdb|\n",
      "|    team22_projectdb|\n",
      "|    team23_projectdb|\n",
      "|    team24_projectdb|\n",
      "|    team25_projectdb|\n",
      "|    team26_projectdb|\n",
      "|    team27_projectdb|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES;\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff740cc-e16f-4338-913b-38c2c3181759",
   "metadata": {},
   "source": [
    "### List all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c66ed2a-3c11-43be-b564-8c48facf7a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table(name='acquisitions', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='degrees', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='funding_rounds', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='funding_rounds_part', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='funds', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='investments', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='ipos', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='milestones', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='objects', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='objects_part', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='offices', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='people', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='q1_results', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='q2_results', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='q3_results', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='relationships', database='team13_projectdb', description=None, tableType='EXTERNAL', isTemporary=False)]\n"
     ]
    }
   ],
   "source": [
    "print(spark.catalog.listTables(\"team13_projectdb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3edd2-c0b4-456f-82d1-2c033a8d5e41",
   "metadata": {},
   "source": [
    "### Read Hive tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e93ce30-1b85-40c4-8d94-8c3ffcbc1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = spark.read.format(\"avro\").table('team13_projectdb.objects_part')\n",
    "\n",
    "fund_rounds = spark.read.format(\"avro\").table('team13_projectdb.funding_rounds_part')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a6c089-c75c-4974-a9a0-2466227583a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ML Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a04a0a-9d25-4655-9538-e7a2abd02fac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7659be-c6f9-47f1-a43f-9b9b75ee93f4",
   "metadata": {},
   "source": [
    "#### Feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100093a7-e039-412d-a123-217c8995e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and the label\n",
    "obj_features = ['id', 'status', 'category_code', 'country_code', 'investment_rounds', 'invested_companies', 'milestones', 'relationships']\n",
    "\n",
    "fund_features = ['object_id', 'funded_at', 'funding_round_type', 'participants', 'is_first_round', 'is_last_round']\n",
    "label = 'raised_amount_usd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e09cf2-a117-4667-92a8-87df44f6b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = objects.select(obj_features)\n",
    "fund_rounds = fund_rounds.select(fund_features + [label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d62b31f1-160e-4aa3-8a54-ee7ccac7fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tables to form one Dataframe for the ML task\n",
    "final = objects.join(fund_rounds, objects['id'] == fund_rounds['object_id'], how='right').drop('id').drop('object_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2749764a-2741-4ac5-9b21-9ebbd25ba39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = final.approxQuantile(\"raised_amount_usd\", [0.25, 0.75], 0)\n",
    "\n",
    "bottom = quantiles[0]\n",
    "top = quantiles[1]\n",
    "\n",
    "final = final.filter((final['raised_amount_usd'] >= bottom) & (final['raised_amount_usd'] <= top))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcea836e-e374-41ab-bf3c-c7da9a804065",
   "metadata": {},
   "outputs": [],
   "source": [
    "leisure = ['games_video', 'photo_video', 'social', 'hospitality', 'sports', 'fashion', 'messaging', 'music']\n",
    "bizsupport = ['network_hosting', 'advertising', 'enterprise', 'consulting', 'analytics', 'public_relations', 'security', 'legal']\n",
    "building = ['cleantech', 'manufacturing', 'semiconductor', 'automotive', 'real_eastate', 'nanotech']\n",
    "petcare = ['pets']\n",
    "travel = ['travel', 'transportation']\n",
    "health = ['health', 'medical', 'biotech']\n",
    "other = ['web', 'other', 'mobile', 'software', 'finance', 'education', 'ecommerce', 'search', 'hardware', 'news', 'government', 'nonprofit', 'local']\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def map_category_code(category_code):\n",
    "    if category_code in leisure:\n",
    "        return 'leisure'\n",
    "    elif category_code in bizsupport:\n",
    "        return 'bizsupport'\n",
    "    elif category_code in building:\n",
    "        return 'building'\n",
    "    elif category_code in petcare:\n",
    "        return 'petcare'\n",
    "    elif category_code in travel:\n",
    "        return 'travel'\n",
    "    elif category_code in health:\n",
    "        return 'health'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "final = final.withColumn('category_code', map_category_code(final['category_code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32b75737-5b5c-4758-be86-0d5154c2ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Africa = ['AGO', 'BDI', 'BEN', 'BWA', 'CIV', 'CMR', 'DZA', 'EGY', 'ETH', 'GHA', 'GIN', 'KEN', 'LSO', 'MAR', 'MDG', 'MUS', 'NAM', 'NER','NGA', 'REU','RWA', 'SDN','SEN', 'SLE', 'SOM','SWZ', 'SYC', 'TUN', 'TZA', 'UGA', 'ZAF', 'ZMB', 'ZWE']\n",
    "Asia = ['AFG', 'ARE', 'BGD', 'BHR', 'BRN', 'CHN', 'HKG', 'IDN', 'IND', 'IOT', 'IRN', 'IRQ', 'ISR','JOR', 'JPN', 'KAZ', 'KGZ', 'KHM', 'KOR', 'KWT','LAO', 'LBN', 'LKA', 'MAC', 'MDV', 'MMR', 'MYS', 'NPL', 'OMN', 'PAK', 'PCN','PHL','PRK','PST', 'QAT', 'SAU', 'SGP','SYR', 'THA', 'TJK', 'TWN', 'UZB', 'VNM', 'YEM']\n",
    "Europe = ['AIA', 'ALB', 'AND', 'ARM', 'AUT', 'AZE', 'BEL', 'BGR','BIH', 'BLR', 'CHE', 'CYP', 'CZE', 'DEU', 'DNK','ESP', 'EST', 'FIN', 'FRA', 'GBR', 'GEO', 'GIB', 'GLB', 'GRC', 'HRV', 'HUN', 'IRL', 'ISL', 'ITA', 'LIE', 'LTU','LUX', 'LVA', 'MCO', 'MDA', 'MKD', 'MLT', 'NLD', 'NOR', 'POL', 'PRT', 'ROM', 'RUS', 'SMR', 'SVK', 'SVN','SWE', 'TUR', 'UKR']\n",
    "North_America = ['ATG', 'BHS','BLZ', 'BMU', 'BRB', 'CAN', 'CRI','CUB','CYM', 'DMA', 'GRD', 'GTM', 'HND', 'HTI', 'JAM', 'MEX', 'MTQ', 'PAN', 'PRI', 'SLV', 'UMI','USA', 'VGB', 'VIR']\n",
    "South_America = ['ARG', 'BOL', 'BRA', 'CHL', 'COL', 'DOM', 'ECU', 'NIC', 'PER', 'PRY', 'SUR', 'TTO', 'URY','VEN', 'VCT']\n",
    "Other = ['ANT', 'ARA', 'AUS', 'CSS', 'FST', 'HMI','NCL', 'NFK','NRU', 'NZL']\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def map_country(country_code):\n",
    "    if country_code in Africa:\n",
    "        return 'Africa'\n",
    "    elif country_code in Asia:\n",
    "        return 'Asia'\n",
    "    elif country_code in Europe:\n",
    "        return 'Europe'\n",
    "    elif country_code in North_America:\n",
    "        return 'North_America'\n",
    "    elif country_code in South_America:\n",
    "        return 'South_America'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "    \n",
    "final = final.withColumn('country_code', map_country(final['country_code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "173d8a11-c009-4a18-a63f-00ca03731772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split funded_at with datetime to year, month and day\n",
    "split_col = F.split(F.to_date(\"funded_at\"), \"-\")\n",
    "final = final.withColumn(\"funded_year\", split_col.getItem(0).cast(IntegerType())) \\\n",
    "            .withColumn(\"funded_month\", split_col.getItem(1).cast(IntegerType())) \\\n",
    "            .withColumn(\"funded_day\", split_col.getItem(2).cast(IntegerType()))\n",
    "# Remove funded_at\n",
    "final = final.drop(\"funded_at\")\n",
    "\n",
    "# Drop all records which contain nulls\n",
    "final = final.na.drop()\n",
    "\n",
    "# Convert raised_amount_usd (label) to mln usd\n",
    "# final = final.withColumn(\"raised_amount_usd\", col(\"raised_amount_usd\")/1000000)\n",
    "final = final.withColumn(\"raised_amount_usd\", F.log10(col(\"raised_amount_usd\")))\n",
    "                        \n",
    "\n",
    "final = final.na.fill(0, \"raised_amount_usd\")\n",
    "\n",
    "# Rename label\n",
    "final = final.withColumnRenamed(\"raised_amount_usd\", \"label\")\n",
    "\n",
    "# Saving intermediate results\n",
    "final = final.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04711d8f-c32b-4b76-9f65-79205da45baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the DataFrame: 26259 rows, 15 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the DataFrame: {} rows, {} columns\".format(final.count(), len(final.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c5b678f-0c4e-4056-ab99-8682147ef676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- status: string (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- investment_rounds: integer (nullable = true)\n",
      " |-- invested_companies: integer (nullable = true)\n",
      " |-- milestones: integer (nullable = true)\n",
      " |-- relationships: integer (nullable = true)\n",
      " |-- funding_round_type: string (nullable = true)\n",
      " |-- participants: integer (nullable = true)\n",
      " |-- is_first_round: integer (nullable = true)\n",
      " |-- is_last_round: integer (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- funded_year: integer (nullable = true)\n",
      " |-- funded_month: integer (nullable = true)\n",
      " |-- funded_day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee78b23a-4cfe-4db6-b026-0de99b4a63b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------+-----------------+------------------+----------+-------------+------------------+------------+--------------+-------------+------------------+-----------+------------+----------+\n",
      "|   status|category_code| country_code|investment_rounds|invested_companies|milestones|relationships|funding_round_type|participants|is_first_round|is_last_round|             label|funded_year|funded_month|funded_day|\n",
      "+---------+-------------+-------------+-----------------+------------------+----------+-------------+------------------+------------+--------------+-------------+------------------+-----------+------------+----------+\n",
      "|   closed|        other|North_America|                0|                 0|         3|            4|          series-a|           0|             1|            0| 6.361727836017593|       2011|           4|        25|\n",
      "|operating|        other|North_America|                0|                 0|         2|           14|          series-a|           0|             0|            1| 5.954242509439325|       2008|           5|        31|\n",
      "|operating|        other|North_America|                0|                 0|         2|           14|          series-b|           1|             0|            0| 6.301029995663981|       2009|           9|         1|\n",
      "|operating|        other|North_America|                0|                 0|         2|           14|         series-c+|           0|             1|            0| 6.477121254719663|       2012|           9|        12|\n",
      "|operating|        other|North_America|                0|                 0|         0|            6|          series-b|           2|             0|            1| 6.544068044350276|       2005|           1|        16|\n",
      "|operating|        other|North_America|                0|                 0|         0|            6|          series-a|           0|             0|            0| 6.477121254719663|       2008|           1|         1|\n",
      "|operating|        other|North_America|                0|                 0|         2|           13|          series-a|           1|             1|            0|6.3226513062053655|       2013|           7|        15|\n",
      "|operating|       health|        Other|                0|                 0|         0|            0|           venture|           0|             0|            1| 5.999999565705301|       2012|           1|        26|\n",
      "|operating|       health|        Other|                0|                 0|         0|            0|             angel|           1|             0|            0|               6.0|       2012|           2|         2|\n",
      "|operating|       health|        Other|                0|                 0|         0|            0|           venture|           2|             1|            0|   5.8750612633917|       2012|          10|        11|\n",
      "|operating|      leisure|       Europe|                0|                 0|         3|            5|             angel|           0|             1|            0| 5.477121254719663|       2013|           4|         1|\n",
      "|operating|      leisure|       Europe|                0|                 0|         3|            5|             angel|           0|             0|            1| 5.477121254719663|       2011|           6|        22|\n",
      "|operating|        other|North_America|                0|                 0|         0|            1|           venture|           0|             1|            1|5.4913630947819545|       2012|          11|         6|\n",
      "|operating|        other|North_America|                0|                 0|         0|            0|           venture|           0|             1|            0| 5.778151250383644|       2012|           5|        22|\n",
      "|operating|       health|       Europe|                0|                 0|         0|            0|          series-b|           3|             1|            1| 6.663092864465058|       2012|           4|        12|\n",
      "|   closed|      leisure|North_America|                0|                 0|         0|            1|          series-b|           1|             1|            0| 6.698970004336019|       2008|           9|        16|\n",
      "|operating|      leisure|North_America|                0|                 0|         2|            1|             angel|           0|             1|            1| 5.989004615698537|       2012|          12|        19|\n",
      "|operating|   bizsupport|North_America|                0|                 0|         0|            0|             angel|           0|             0|            1| 6.096910013008056|       2012|          10|        10|\n",
      "|operating|   bizsupport|North_America|                0|                 0|         0|            0|           venture|           0|             1|            0|5.7877416476056585|       2013|          12|         4|\n",
      "|operating|     building|North_America|                0|                 0|         2|            2|             angel|           4|             1|            1| 5.477121254719663|       2013|           9|         5|\n",
      "+---------+-------------+-------------+-----------------+------------------+----------+-------------+------------------+------------+--------------+-------------+------------------+-----------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201afa64-ca41-43ee-a8fd-afd3d1225c5e",
   "metadata": {},
   "source": [
    "#### Building the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b040e880-03e7-44a3-ab80-02662b66509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract categorical, numerical and cyclical features\n",
    "categorical_cols = ['status', 'funding_round_type', 'category_code', 'country_code']\n",
    "\n",
    "numerical_cols = ['investment_rounds', 'invested_companies', 'milestones', 'relationships', 'funded_year', 'participants', 'is_first_round', 'is_last_round']\n",
    "\n",
    "cyclical_cols = ['funded_month', 'funded_day']\n",
    "periods = [12, 31]  # periods for months and days accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87304e13-0cf5-42b6-8cd5-692542aea18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a custom tranformer to encode cyclical features\n",
    "class CyclicTransformer(Transformer, HasInputCol, HasOutputCol, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    inputCol = Param(Params._dummy(), \"inputCol\", \"input column name.\", typeConverter=TypeConverters.toString)\n",
    "    outputCol = Param(Params._dummy(), \"outputCol\", \"output column name.\", typeConverter=TypeConverters.toString)\n",
    "  \n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol: str = \"input\", outputCol: str = \"output\", period: int = 12):\n",
    "        super(CyclicTransformer, self).__init__()\n",
    "        self._setDefault(inputCol=None, outputCol=None)\n",
    "        kwargs = self._input_kwargs\n",
    "        del(kwargs[\"period\"])\n",
    "        self.set_params(**kwargs)\n",
    "        self.period = period\n",
    "    \n",
    "    @keyword_only\n",
    "    def set_params(self, inputCol: str = \"input\", outputCol: str = \"output\"):\n",
    "        kwargs = self._input_kwargs\n",
    "        self._set(**kwargs)\n",
    "    \n",
    "    def getInputCol(self):\n",
    "        return self.getOrDefault(self.inputCol)\n",
    "  \n",
    "    def getOutputCol(self):\n",
    "        return self.getOrDefault(self.outputCol)\n",
    "  \n",
    "    def _transform(self, df: DataFrame):\n",
    "        input_col = self.getInputCol()\n",
    "        output_col = self.getOutputCol()\n",
    "        \n",
    "        sin_col = sin(2 * math.pi * df[input_col] / self.period) \n",
    "        cos_col = cos(2 * math.pi * df[input_col] / self.period)\n",
    "       \n",
    "        return df.withColumn(output_col + \"_sin\", sin_col).withColumn(output_col + \"_cos\", cos_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bdc866e-010f-423c-94af-c9a8c318da15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------+-----------------+------------------+----------+-------------+------------------+------------+--------------+-------------+------------------+-----------+------------+----------+--------------+--------------------------+---------------------+--------------------+----------------------+----------------------------------+-----------------------------+----------------------------+------------------------+------------------------+----------------------+----------------------+--------------------+\n",
      "|   status|category_code| country_code|investment_rounds|invested_companies|milestones|relationships|funding_round_type|participants|is_first_round|is_last_round|             label|funded_year|funded_month|funded_day|status_indexed|funding_round_type_indexed|category_code_indexed|country_code_indexed|status_indexed_encoded|funding_round_type_indexed_encoded|category_code_indexed_encoded|country_code_indexed_encoded|funded_month_cyc_enc_sin|funded_month_cyc_enc_cos|funded_day_cyc_enc_sin|funded_day_cyc_enc_cos|            features|\n",
      "+---------+-------------+-------------+-----------------+------------------+----------+-------------+------------------+------------+--------------+-------------+------------------+-----------+------------+----------+--------------+--------------------------+---------------------+--------------------+----------------------+----------------------------------+-----------------------------+----------------------------+------------------------+------------------------+----------------------+----------------------+--------------------+\n",
      "|   closed|        other|North_America|                0|                 0|         3|            4|          series-a|           0|             1|            0| 6.361727836017593|       2011|           4|        25|           2.0|                       1.0|                  0.0|                 0.0|         (3,[2],[1.0])|                     (8,[1],[1.0])|                (6,[0],[1.0])|               (5,[0],[1.0])|      0.8660254037844387|     -0.4999999999999998|   -0.9377521321470804|    0.3473052528448203|(34,[2,4,11,17,22...|\n",
      "|operating|        other|North_America|                0|                 0|         2|           14|          series-a|           0|             0|            1| 5.954242509439325|       2008|           5|        31|           0.0|                       1.0|                  0.0|                 0.0|         (3,[0],[1.0])|                     (8,[1],[1.0])|                (6,[0],[1.0])|               (5,[0],[1.0])|     0.49999999999999994|     -0.8660254037844387|  -2.44929359829470...|                   1.0|(34,[0,4,11,17,22...|\n",
      "|operating|        other|North_America|                0|                 0|         2|           14|          series-b|           1|             0|            0| 6.301029995663981|       2009|           9|         1|           0.0|                       4.0|                  0.0|                 0.0|         (3,[0],[1.0])|                     (8,[4],[1.0])|                (6,[0],[1.0])|               (5,[0],[1.0])|                    -1.0|    -1.83697019872102...|   0.20129852008866006|    0.9795299412524945|(34,[0,7,11,17,22...|\n",
      "|operating|        other|North_America|                0|                 0|         2|           14|         series-c+|           0|             1|            0| 6.477121254719663|       2012|           9|        12|           0.0|                       5.0|                  0.0|                 0.0|         (3,[0],[1.0])|                     (8,[5],[1.0])|                (6,[0],[1.0])|               (5,[0],[1.0])|                    -1.0|    -1.83697019872102...|    0.6513724827222223|   -0.7587581226927909|(34,[0,8,11,17,22...|\n",
      "|operating|        other|North_America|                0|                 0|         0|            6|          series-b|           2|             0|            1| 6.544068044350276|       2005|           1|        16|           0.0|                       4.0|                  0.0|                 0.0|         (3,[0],[1.0])|                     (8,[4],[1.0])|                (6,[0],[1.0])|               (5,[0],[1.0])|     0.49999999999999994|      0.8660254037844387|  -0.10116832198743204|   -0.9948693233918952|(34,[0,7,11,17,22...|\n",
      "|operating|        other|North_America|                0|                 0|         0|            6|          series-a|           0|             0|            0| 6.477121254719663|       2008|           1|         1|           0.0|                       1.0|                  0.0|                 0.0|         (3,[0],[1.0])|                     (8,[1],[1.0])|                (6,[0],[1.0])|               (5,[0],[1.0])|     0.49999999999999994|      0.8660254037844387|   0.20129852008866006|    0.9795299412524945|(34,[0,4,11,17,22...|\n",
      "|operating|        other|North_America|                0|                 0|         2|           13|          series-a|           1|             1|            0|6.3226513062053655|       2013|           7|        15|           0.0|                       1.0|                  0.0|                 0.0|         (3,[0],[1.0])|                     (8,[1],[1.0])|                (6,[0],[1.0])|               (5,[0],[1.0])|     -0.4999999999999997|     -0.8660254037844388|   0.10116832198743272|    -0.994869323391895|(34,[0,4,11,17,22...|\n",
      "|operating|       health|        Other|                0|                 0|         0|            0|           venture|           0|             0|            1| 5.999999565705301|       2012|           1|        26|           0.0|                       0.0|                  2.0|                 3.0|         (3,[0],[1.0])|                     (8,[0],[1.0])|                (6,[2],[1.0])|               (5,[3],[1.0])|     0.49999999999999994|      0.8660254037844387|    -0.848644257494751|    0.5289640103269624|(34,[0,3,13,20,22...|\n",
      "|operating|       health|        Other|                0|                 0|         0|            0|             angel|           1|             0|            0|               6.0|       2012|           2|         2|           0.0|                       2.0|                  2.0|                 3.0|         (3,[0],[1.0])|                     (8,[2],[1.0])|                (6,[2],[1.0])|               (5,[3],[1.0])|      0.8660254037844386|      0.5000000000000001|   0.39435585511331855|    0.9189578116202306|(34,[0,5,13,20,22...|\n",
      "|operating|       health|        Other|                0|                 0|         0|            0|           venture|           2|             1|            0|   5.8750612633917|       2012|          10|        11|           0.0|                       0.0|                  2.0|                 3.0|         (3,[0],[1.0])|                     (8,[0],[1.0])|                (6,[2],[1.0])|               (5,[3],[1.0])|     -0.8660254037844386|      0.5000000000000001|    0.7907757369376989|   -0.6121059825476626|(34,[0,3,13,20,22...|\n",
      "|operating|      leisure|       Europe|                0|                 0|         3|            5|             angel|           0|             1|            0| 5.477121254719663|       2013|           4|         1|           0.0|                       2.0|                  3.0|                 1.0|         (3,[0],[1.0])|                     (8,[2],[1.0])|                (6,[3],[1.0])|               (5,[1],[1.0])|      0.8660254037844387|     -0.4999999999999998|   0.20129852008866006|    0.9795299412524945|(34,[0,5,14,18,22...|\n",
      "|operating|      leisure|       Europe|                0|                 0|         3|            5|             angel|           0|             0|            1| 5.477121254719663|       2011|           6|        22|           0.0|                       2.0|                  3.0|                 1.0|         (3,[0],[1.0])|                     (8,[2],[1.0])|                (6,[3],[1.0])|               (5,[1],[1.0])|    1.224646799147353...|                    -1.0|   -0.9680771188662041|   -0.2506525322587213|(34,[0,5,14,18,22...|\n",
      "|operating|        other|North_America|                0|                 0|         0|            1|           venture|           0|             1|            1|5.4913630947819545|       2012|          11|         6|           0.0|                       0.0|                  0.0|                 0.0|         (3,[0],[1.0])|                     (8,[0],[1.0])|                (6,[0],[1.0])|               (5,[0],[1.0])|     -0.5000000000000004|      0.8660254037844384|    0.9377521321470804|    0.3473052528448203|(34,[0,3,11,17,22...|\n",
      "|operating|        other|North_America|                0|                 0|         0|            0|           venture|           0|             1|            0| 5.778151250383644|       2012|           5|        22|           0.0|                       0.0|                  0.0|                 0.0|         (3,[0],[1.0])|                     (8,[0],[1.0])|                (6,[0],[1.0])|               (5,[0],[1.0])|     0.49999999999999994|     -0.8660254037844387|   -0.9680771188662041|   -0.2506525322587213|(34,[0,3,11,17,22...|\n",
      "|operating|       health|       Europe|                0|                 0|         0|            0|          series-b|           3|             1|            1| 6.663092864465058|       2012|           4|        12|           0.0|                       4.0|                  2.0|                 1.0|         (3,[0],[1.0])|                     (8,[4],[1.0])|                (6,[2],[1.0])|               (5,[1],[1.0])|      0.8660254037844387|     -0.4999999999999998|    0.6513724827222223|   -0.7587581226927909|(34,[0,7,13,18,22...|\n",
      "|   closed|      leisure|North_America|                0|                 0|         0|            1|          series-b|           1|             1|            0| 6.698970004336019|       2008|           9|        16|           2.0|                       4.0|                  3.0|                 0.0|         (3,[2],[1.0])|                     (8,[4],[1.0])|                (6,[3],[1.0])|               (5,[0],[1.0])|                    -1.0|    -1.83697019872102...|  -0.10116832198743204|   -0.9948693233918952|(34,[2,7,14,17,22...|\n",
      "|operating|      leisure|North_America|                0|                 0|         2|            1|             angel|           0|             1|            1| 5.989004615698537|       2012|          12|        19|           0.0|                       2.0|                  3.0|                 0.0|         (3,[0],[1.0])|                     (8,[2],[1.0])|                (6,[3],[1.0])|               (5,[0],[1.0])|    -2.44929359829470...|                     1.0|    -0.651372482722222|   -0.7587581226927911|(34,[0,5,14,17,22...|\n",
      "|operating|   bizsupport|North_America|                0|                 0|         0|            0|             angel|           0|             0|            1| 6.096910013008056|       2012|          10|        10|           0.0|                       2.0|                  1.0|                 0.0|         (3,[0],[1.0])|                     (8,[2],[1.0])|                (6,[1],[1.0])|               (5,[0],[1.0])|     -0.8660254037844386|      0.5000000000000001|    0.8978045395707416|   -0.4403941515576344|(34,[0,5,12,17,22...|\n",
      "|operating|   bizsupport|North_America|                0|                 0|         0|            0|           venture|           0|             1|            0|5.7877416476056585|       2013|          12|         4|           0.0|                       0.0|                  1.0|                 0.0|         (3,[0],[1.0])|                     (8,[0],[1.0])|                (6,[1],[1.0])|               (5,[0],[1.0])|    -2.44929359829470...|                     1.0|      0.72479278722912|    0.6889669190756866|(34,[0,3,12,17,22...|\n",
      "|operating|     building|North_America|                0|                 0|         2|            2|             angel|           4|             1|            1| 5.477121254719663|       2013|           9|         5|           0.0|                       2.0|                  4.0|                 0.0|         (3,[0],[1.0])|                     (8,[2],[1.0])|                (6,[4],[1.0])|               (5,[0],[1.0])|                    -1.0|    -1.83697019872102...|    0.8486442574947509|    0.5289640103269624|(34,[0,5,15,17,22...|\n",
      "+---------+-------------+-------------+-----------------+------------------+----------+-------------+------------------+------------+--------------+-------------+------------------+-----------+------------+----------+--------------+--------------------------+---------------------+--------------------+----------------------+----------------------------------+-----------------------------+----------------------------+------------------------+------------------------+----------------------+----------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create String indexer to assign index for the string fields where each unique string will get a unique index\n",
    "indexers = [StringIndexer(inputCol=c, \n",
    "                           outputCol=\"{0}_indexed\".format(c)).setHandleInvalid(\"skip\") for c in categorical_cols]\n",
    "\n",
    "# Encode strings using One Hot encoding\n",
    "encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), \n",
    "                           outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) for indexer in indexers]\n",
    "\n",
    "# Encode cyclical features using custom Cyclic Transformer\n",
    "cyclic_transformers = [CyclicTransformer(inputCol=col, \n",
    "                                         outputCol=col + \"_cyc_enc\", \n",
    "                                         period=period) for col, period in zip(cyclical_cols, periods)]\n",
    "\n",
    "# This will concatenate the input cols into a single column\n",
    "assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders] + \n",
    "                            [transformer.getOutputCol() + '_sin' for transformer in cyclic_transformers] + \n",
    "                            [transformer.getOutputCol() + '_cos' for transformer in cyclic_transformers] + \n",
    "                            numerical_cols, \n",
    "                            outputCol= \"features\")\n",
    "\n",
    "# scaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\")\n",
    "\n",
    "# Create a pipeline to use only a single fit and transform on the data\n",
    "pipeline = Pipeline(stages=indexers + encoders + cyclic_transformers + [assembler])\n",
    "\n",
    "# Fit the pipeline ==> This will call the fit functions for all transformers if exist\n",
    "model = pipeline.fit(final)\n",
    "\n",
    "# Fit the pipeline ==> This will call the transform functions for all transformers\n",
    "data = model.transform(final)\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09c32620-1fe3-4f38-a961-9cbd8eafbf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|             label|\n",
      "+--------------------+------------------+\n",
      "|(34,[2,4,11,17,22...| 6.361727836017593|\n",
      "|(34,[0,4,11,17,22...| 5.954242509439325|\n",
      "|(34,[0,7,11,17,22...| 6.301029995663981|\n",
      "|(34,[0,8,11,17,22...| 6.477121254719663|\n",
      "|(34,[0,7,11,17,22...| 6.544068044350276|\n",
      "|(34,[0,4,11,17,22...| 6.477121254719663|\n",
      "|(34,[0,4,11,17,22...|6.3226513062053655|\n",
      "|(34,[0,3,13,20,22...| 5.999999565705301|\n",
      "|(34,[0,5,13,20,22...|               6.0|\n",
      "|(34,[0,3,13,20,22...|   5.8750612633917|\n",
      "|(34,[0,5,14,18,22...| 5.477121254719663|\n",
      "|(34,[0,5,14,18,22...| 5.477121254719663|\n",
      "|(34,[0,3,11,17,22...|5.4913630947819545|\n",
      "|(34,[0,3,11,17,22...| 5.778151250383644|\n",
      "|(34,[0,7,13,18,22...| 6.663092864465058|\n",
      "|(34,[2,7,14,17,22...| 6.698970004336019|\n",
      "|(34,[0,5,14,17,22...| 5.989004615698537|\n",
      "|(34,[0,5,12,17,22...| 6.096910013008056|\n",
      "|(34,[0,3,12,17,22...|5.7877416476056585|\n",
      "|(34,[0,5,15,17,22...| 5.477121254719663|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Delete all features and keep only the features and label columns\n",
    "data = data.select([\"features\", \"label\"])\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fd1cf-ec02-45ce-833e-c942fdc9c7a8",
   "metadata": {},
   "source": [
    "#### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a51cca6-484d-468c-9fef-19b8d1265678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% training and 30% test (it is not stratified)\n",
    "(train_data, test_data) = data.randomSplit([0.7, 0.3], seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac90ec5b-38ca-435d-8bea-d776752f1cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data: (18343, 2)\n",
      "Size of test data: (7916, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training data: ({}, {})\".format(train_data.count(), len(train_data.columns)))\n",
    "print(\"Size of test data: ({}, {})\".format(test_data.count(), len(test_data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df8e3591-d100-4818-b3c1-2fd0f99ddbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split ratio: 0.7, 0.3\n"
     ]
    }
   ],
   "source": [
    "# Check the train test split ratio\n",
    "print(\"Split ratio: {}, {}\".format(round(train_data.count() / data.count(), 2), round(test_data.count() / data.count(), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee1fcb42-ad3e-4edd-b2e4-62af53c21c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A function to run commands\n",
    "# def run(command):\n",
    "#     return os.popen(command).read()\n",
    "\n",
    "# train_data.select(\"features\", \"label\")\\\n",
    "#     .coalesce(1)\\\n",
    "#     .write\\\n",
    "#     .mode(\"overwrite\")\\\n",
    "#     .format(\"json\")\\\n",
    "#     .save(\"project/data/train\")\n",
    "\n",
    "# # Run it from root directory of the repository\n",
    "# run(\"hdfs dfs -cat project/data/train/*.json > data/train.json\")\n",
    "\n",
    "# test_data.select(\"features\", \"label\")\\\n",
    "#     .coalesce(1)\\\n",
    "#     .write\\\n",
    "#     .mode(\"overwrite\")\\\n",
    "#     .format(\"json\")\\\n",
    "#     .save(\"project/data/test\")\n",
    "\n",
    "# # Run it from root directory of the repository\n",
    "# run(\"hdfs dfs -cat project/data/test/*.json > data/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e08cf-dc38-47ef-ba12-95ac750977bb",
   "metadata": {},
   "source": [
    "###  Modeling: First model\n",
    "\n",
    "First model is Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77822e83-d529-4dbe-a6d5-d94cf0387325",
   "metadata": {},
   "source": [
    "#### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da2fda76-fc2a-44b5-92ab-a510eb47184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Linear Regression Model\n",
    "lr = LinearRegression(maxIter=250, loss = \"huber\")\n",
    "\n",
    "# Fit the data to the lr model\n",
    "model_lr = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eeb103-ace9-46d7-a978-a2f253c86157",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7588ce1-7118-4467-9b9a-1abd182898c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|            features|             label|        prediction|\n",
      "+--------------------+------------------+------------------+\n",
      "|(34,[0,3,11,17,22...| 4400000.000000005|1793648.9556791098|\n",
      "|(34,[0,3,11,17,22...|2794999.9999999986|1476224.7873354186|\n",
      "|(34,[0,3,11,17,22...|3059999.9999999977|1531657.2088653855|\n",
      "|(34,[0,3,11,17,22...| 480006.0000000001| 1413245.765755045|\n",
      "|(34,[0,3,11,17,22...| 4999999.999999999|1500059.4492883375|\n",
      "|(34,[0,3,11,17,22...| 702679.0000000006|1501051.6832866487|\n",
      "|(34,[0,3,11,17,22...|1150000.0000000002|1311050.2668687566|\n",
      "|(34,[0,3,11,17,22...| 600000.0000000003|1511968.7845707606|\n",
      "|(34,[0,3,11,21,22...| 2708825.000000002|1359345.5196104718|\n",
      "|(34,[0,3,13,17,22...| 530000.0000000001|  1872705.93126128|\n",
      "|(34,[0,3,13,17,22...| 2638999.999999999|1787338.6203485902|\n",
      "|(34,[0,3,13,17,22...|         1000000.0|1674777.5296831373|\n",
      "|(34,[0,3,13,18,22...| 5118944.999999998|1930027.0689808875|\n",
      "|(34,[0,3,13,18,22...|1464244.0000000007| 1907038.075733831|\n",
      "|(34,[0,4,11,17,22...|1700000.0000000007|2739489.5072072768|\n",
      "|(34,[0,4,11,17,22...|499999.99999999994| 2284672.954791282|\n",
      "|(34,[0,4,11,17,22...| 3000000.000000001|2275263.0632405803|\n",
      "|(34,[0,4,11,17,22...|         2850000.0|2709617.0100339223|\n",
      "|(34,[0,4,12,17,22...| 1600000.000000001| 2586340.823980395|\n",
      "|(34,[0,4,12,17,22...| 3000000.000000001| 2121037.338542594|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the data (Prediction)\n",
    "predictions = model_lr.transform(test_data)\n",
    "\n",
    "predictions = predictions.withColumn(\"label\", F.pow(10, \"label\"))\n",
    "predictions = predictions.withColumn(\"prediction\", F.pow(10, \"prediction\"))\n",
    "\n",
    "\n",
    "# Display the predictions\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9c359-9a96-4274-8c31-ab5a5d877ac2",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d36eb6d1-b1d3-41c4-ba09-1c656c9d5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import Evaluator\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.sql import Row\n",
    "\n",
    "class MAPEEvaluator(Evaluator):\n",
    "    def __init__(self, predictionCol=\"prediction\", labelCol=\"label\"):\n",
    "        self.predictionCol = predictionCol\n",
    "        self.labelCol = labelCol\n",
    "\n",
    "    def _evaluate(self, dataset):\n",
    "        \"\"\"\n",
    "        Calculates the Mean Absolute Percentage Error (MAPE) for regression tasks.\n",
    "        \"\"\"\n",
    "        predictionAndLabels = dataset.select(self.predictionCol, self.labelCol).rdd.map(\n",
    "            lambda row: (float(row[self.predictionCol]), float(row[self.labelCol]))\n",
    "        )\n",
    "\n",
    "        absolutePercentageErrors = predictionAndLabels.map(\n",
    "            lambda x: abs((x[1] - x[0]) / x[1]) if x[1] !=0 else 1\n",
    "        )\n",
    "\n",
    "        mape = absolutePercentageErrors.mean()\n",
    "\n",
    "        return mape\n",
    "\n",
    "    def isLargerBetter(self):\n",
    "        \"\"\"\n",
    "        Indicates whether a larger value of the metric is better.\n",
    "        \"\"\"\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71665ee1-70b8-4736-8610-fcf8a6d6e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1562668.6209236805\n",
      "R2 on test data = 0.23395541908638073\n",
      "Mean Absolute Percentage Error on test data = 0.7771505664070809\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the model\n",
    "evaluator1_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator1_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "evaluator1_mape = MAPEEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse_lr = evaluator1_rmse.evaluate(predictions)\n",
    "r2_lr = evaluator1_r2.evaluate(predictions)\n",
    "mape_lr = evaluator1_mape.evaluate(predictions)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = {}\".format(rmse_lr))\n",
    "print(\"R2 on test data = {}\".format(r2_lr))\n",
    "print(\"Mean Absolute Percentage Error on test data = {}\".format(mape_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d52124-da01-46b9-b522-9baa492c63f5",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b28b6e-1990-48b6-8efe-3531d16ad393",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParamGridBuilder()\n",
    "grid = grid.addGrid(model_lr.aggregationDepth, [2, 3, 4]) \\\n",
    "                    .addGrid(model_lr.regParam, [0.0, 0.001, 0.1, 0.3, 0.5]) \\\n",
    "                    .build()\n",
    "\n",
    "cv = CrossValidator(estimator=lr, \n",
    "                    estimatorParamMaps=grid, \n",
    "                    evaluator=evaluator1_mape,\n",
    "                    parallelism=5,\n",
    "                    numFolds=3)\n",
    "\n",
    "cvModel = cv.fit(train_data)\n",
    "bestModel = cvModel.bestModel\n",
    "bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d202e-e8d6-46ee-beee-d939d797a310",
   "metadata": {},
   "source": [
    "#### Select the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6168cad-499f-4def-a4d6-59c6beda713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = bestModel\n",
    "pprint(model1.extractParamMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851f892-ff36-43fa-a175-a0e9d635d19e",
   "metadata": {},
   "source": [
    "#### Save the model to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8bc3e-1b27-4ce2-b027-12c148555b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.write().overwrite().save(\"project/models/model1\")\n",
    "\n",
    "# # Run it from root directory of the repository\n",
    "# run(\"hdfs dfs -get project/models/model1 models/model1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8343a76-c232-41fe-9487-c2e719b56b45",
   "metadata": {},
   "source": [
    "#### Prediction of the best model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70cace-5fb2-4c4e-8d85-5493b8b2c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model1.transform(test_data)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee6b2a-4583-46b0-91bf-9858510a87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions.select(\"label\", \"prediction\")\\\n",
    "#     .coalesce(1)\\\n",
    "#     .write\\\n",
    "#     .mode(\"overwrite\")\\\n",
    "#     .format(\"csv\")\\\n",
    "#     .option(\"sep\", \",\")\\\n",
    "#     .option(\"header\",\"true\")\\\n",
    "#     .save(\"project/output/model1_predictions.csv\")\n",
    "\n",
    "# # Run it from root directory of the repository\n",
    "# run(\"hdfs dfs -cat project/output/model1_predictions.csv/*.csv > output/model1_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75172db9-2a86-4229-8136-8f854b2b58de",
   "metadata": {},
   "source": [
    "#### Evaluation of the best model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3769d14-45ef-4283-b76a-20625ca66fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the best model\n",
    "evaluator1_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator1_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse1 = evaluator1_rmse.evaluate(predictions)\n",
    "r2_1 = evaluator1_r2.evaluate(predictions)\n",
    "mape1 = evaluator1_mape.evaluate(predictions)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = {}\".format(rmse1))\n",
    "print(\"R2 on test data = {}\".format(r2_1))\n",
    "print(\"Mean Absolute Percentage Error on test data = {}\".format(mape1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f7ba0-e1d1-4426-b6ba-1f2a4d44e9ec",
   "metadata": {},
   "source": [
    "###  Modeling: Second model\n",
    "\n",
    "\n",
    "Second model is Gradient-Boosted Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa93d7-63f5-46d8-a3aa-8b47e72304b9",
   "metadata": {},
   "source": [
    "#### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a1412-24c5-4413-a3ae-89f89068fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradient-Boosted Tree regression Model\n",
    "gbt = GBTRegressor()\n",
    "\n",
    "# Fit the data to the model\n",
    "model_gbt = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ddb06c-4fec-4047-bcf7-a645436d68fa",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d21484-717b-4fcd-809c-e096f33c0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data (Prediction)\n",
    "predictions = model_gbt.transform(test_data)\n",
    "\n",
    "# Display the predictions\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99580d05-1477-414f-bd89-e35979fd19af",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c1247-da55-49b4-8fbe-79c59de0a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model\n",
    "evaluator2_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator2_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse_gbt = evaluator2_rmse.evaluate(predictions)\n",
    "r2_gbt = evaluator2_r2.evaluate(predictions)\n",
    "mape_gbt = evaluator1_mape.evaluate(predictions)\n",
    "\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = {}\".format(rmse_gbt))\n",
    "print(\"R2 on test data = {}\".format(r2_gbt))\n",
    "print(\"Mean Absolute Percentage Error on test data = {}\".format(mape_gbt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2019ae74-dc3d-473e-905f-2cf2e76c9786",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eb9bb8-5fbe-46c7-8c9d-27e12964b1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParamGridBuilder()\n",
    "grid = (ParamGridBuilder().addGrid(model_gbt.maxDepth, [5, 10, 15, 20]) \\\n",
    "             .addGrid(model_gbt.lossType, ['absolute', 'squared']) \\\n",
    "             .build())\n",
    "\n",
    "cv = CrossValidator(estimator=gbt, \n",
    "                    estimatorParamMaps=grid, \n",
    "                    evaluator=evaluator1_mape,\n",
    "                    parallelism=5,\n",
    "                    numFolds=3)\n",
    "\n",
    "cvModel = cv.fit(train_data)\n",
    "bestModel = cvModel.bestModel\n",
    "bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7e2db-e91f-4769-8399-f9cf90871962",
   "metadata": {},
   "source": [
    "#### Select the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b819f1-4ce7-4fb2-bb4b-7af5cb8c615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = bestModel\n",
    "pprint(model2.extractParamMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4cad82-5920-4fae-bddb-7bc4439e6c8f",
   "metadata": {},
   "source": [
    "#### Save the model to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be798c64-57ee-4ed8-8b9d-239bb8d83a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.write().overwrite().save(\"project/models/model2\")\n",
    "\n",
    "# # Run it from root directory of the repository\n",
    "# run(\"hdfs dfs -get project/models/model2 models/model2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa82c49-9926-4cea-8f5a-20fc887ce11b",
   "metadata": {},
   "source": [
    "#### Prediction of the best model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a80b4-ea9c-4f1e-922d-23a6713dff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model2.transform(test_data)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1012f2-ee21-4cfc-8670-d7e4718051c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions.select(\"label\", \"prediction\")\\\n",
    "#     .coalesce(1)\\\n",
    "#     .write\\\n",
    "#     .mode(\"overwrite\")\\\n",
    "#     .format(\"csv\")\\\n",
    "#     .option(\"sep\", \",\")\\\n",
    "#     .option(\"header\",\"true\")\\\n",
    "#     .save(\"project/output/model2_predictions.csv\")\n",
    "\n",
    "# # Run it from root directory of the repository\n",
    "# run(\"hdfs dfs -cat project/output/model2_predictions.csv/*.csv > output/model2_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a0a22-0105-4193-8408-c6b0ab76da7a",
   "metadata": {},
   "source": [
    "#### Evaluation of the best model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02fb1a-8451-4081-ac0e-b7b9f8161cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the best model\n",
    "evaluator2_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator2_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse2 = evaluator2_rmse.evaluate(predictions)\n",
    "r2_2 = evaluator2_r2.evaluate(predictions)\n",
    "mape2 = evaluator1_mape.evaluate(predictions)\n",
    "\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = {}\".format(rmse2))\n",
    "print(\"R2 on test data = {}\".format(r2_2))\n",
    "print(\"Mean Absolute Percentage Error on test data = {}\".format(mape2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce31a86-8a4d-4a53-98f7-0045497ed80f",
   "metadata": {},
   "source": [
    "### Compare best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b65664-f4e7-4760-8ba9-fd1f26bdab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to report performance of the models\n",
    "models = [[str(model1), rmse1, r2_1, mape1], [str(model2), rmse2, r2_2, mape2]]\n",
    "\n",
    "df = spark.createDataFrame(models, [\"model\", \"RMSE\", \"R2\", \"MAPE\"])\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe1f6a-25de-43d6-b1b3-7b6d286f4b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save it to HDFS\n",
    "# df.coalesce(1)\\\n",
    "#     .write\\\n",
    "#     .mode(\"overwrite\")\\\n",
    "#     .format(\"csv\")\\\n",
    "#     .option(\"sep\", \",\")\\\n",
    "#     .option(\"header\",\"true\")\\\n",
    "#     .save(\"project/output/evaluation.csv\")\n",
    "\n",
    "# # Run it from root directory of the repository\n",
    "# run(\"hdfs dfs -cat project/output/evaluation.csv/*.csv > output/evaluation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5335b-feea-4dcd-8bbc-b3440d6baf4d",
   "metadata": {},
   "source": [
    "## Stop spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1799175e-f184-4be2-bff7-066558669b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
